{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91279c35",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; background-color: #050A0E; border: 1px solid lightblue;\">\n",
    "    <tr>\n",
    "        <td style=\"direction: rtl; text-align: right; color: #FFF8E7; \">\n",
    "            <h2 style=\"color:#FFF8E7;\">JobTonic</h2>\n",
    "            <span style=\"color:#FFF8E7; font-size: 12px\">\n",
    "                כי חיפוש עבודה ראוי להרגיש כמו התחלה חדשה, לא כמו מסע מייגע.\n",
    "                במקום להיסחף בגלים של מידע, \n",
    "                תנו לנו להיות הרוח שמכוונת את המפרש.\n",
    "                הכלי\n",
    "                 מזקק עבורכם את מהות כל משרה — בבהירות, במהירות, ובדיוק שמחזיר לכם שליטה.\n",
    "                זה לא רק לחפש עבודה. זה לדייק מטרה. זה להתקדם עם ראש צלול, לב פתוח, וביטחון אמיתי.\n",
    "                בכל שלב בדרך – אנחנו האנרגיה שמזיזה אתכם קדימה.\n",
    "            </span>\n",
    "        </td>\n",
    "<td style=\"width: 290px; height: 200px; vertical-align: middle;\">\n",
    "            <img src=\"JobTonic.png\" style=\"width: 100%; height: 100%; display: block;\" />\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b9f46285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "import anthropic\n",
    "import google.generativeai\n",
    "import ollama\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b5a12260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Initialize Google and Anthropic clients\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "MODEL_Claude = \"claude-3-7-sonnet-latest\"\n",
    "claude = anthropic.Anthropic()\n",
    "\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "MODEL_Google = \"gemini-2.0-flash\"\n",
    "google.generativeai.configure()\n",
    "\n",
    "api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "endpoint = os.getenv('ENDPOINT')\n",
    "version = os.getenv('VERSION')\n",
    "deployment = os.getenv('DEPLOYMENT_4_1nano')\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint, \n",
    "    api_key=api_key,\n",
    "    api_version=version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ba200f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with Selenium for dynamic websites.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "\n",
    "        # Set up Selenium WebDriver with Chrome\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--headless')  # Run in headless mode\n",
    "        options.add_argument('--disable-gpu')\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "        # Load the webpage\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Wait for the page to load completely\n",
    "\n",
    "        # Get the page source and parse it with BeautifulSoup\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        driver.quit()  # Close the browser\n",
    "\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f344e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The system prompt for job postings\n",
    "job_posting_system_prompt = \"\"\"\n",
    "    You are an assistant specialized in summarizing job postings.\\n\n",
    "    Your task is to extract and clearly summarize three things from the input job description:\\n\n",
    "    1. How the company describes itself.\\n\n",
    "    2. What the day-to-day responsibilities of the role are.\\n\n",
    "    3. What the qualifications or requirements are to apply.\\n\\n\n",
    "    You will be provided with a text file contains links to job postings. for example:\\n\n",
    "    [https://www.example.com/job/software-engineer, https://www.example.com/job/data-scientist]\n",
    "    Write the summary in plain, professional English. Keep each section concise (1–2 sentences).\\n\n",
    "    Do not copy text verbatim unless necessary. Structure your response under the following headers:\\n\n",
    "    - About the Company\\n\n",
    "    - Role Responsibilities\\n\n",
    "    - Qualifications and Requirements\\n\n",
    "    in addition to the following fields:\\n\n",
    "    - Company Name\\n\n",
    "    - Job URL\\n\n",
    "    - Company Location\\n\n",
    "    - Company Size\\n\n",
    "    keep headers empty if the information is not available.\\n\n",
    "\"\"\"\n",
    "job_posting_system_prompt += \"\\nYou should respond in JSON as in this example:\"\n",
    "job_posting_system_prompt += \"\"\"\n",
    "{\n",
    "    \"company_name\": \"Tech Innovations Inc.\",\n",
    "    \"job_url\": \"https://full.url/goes/here/software-engineer\",\n",
    "    \"company_location\": \"San Francisco, CA\",\n",
    "    \"company_size\": \"500+ employees\",\n",
    "    \"company_description\": \"The company is a leading provider of innovative technology solutions.\",\n",
    "    \"role_responsibilities\": \"The role involves developing software applications and collaborating with cross-functional teams.\",\n",
    "    \"qualifications_requirements\": \"Candidates should have a degree in Computer Science and experience with Python.\"\n",
    "}\n",
    "\"\"\"\n",
    "job_posting_system_prompt += \"\\nIn the case that there are no relevant links, respond with an empty JSON object: {}\"\n",
    "\n",
    "job_posting_system_prompt += \"\\n here is a real example of a job posting:\\n\"\n",
    "job_posting_system_prompt += \"\"\"\n",
    "{\n",
    "  \"company_name\": \"Earnix\",\n",
    "  \"job_url\": \"https://earnix.com/career/0d.f45/automation-engineer/\",\n",
    "  \"company_location\": \"Ramat Gan, Israel\",\n",
    "  \"company_size\": \"201–500 employees\",\n",
    "  \"company_description\": \"Earnix is a premier provider of cloud-based intelligent decisioning solutions for pricing, rating, underwriting, and product personalization in the insurance and banking sectors, serving clients across over 35 countries.\",\n",
    "  \"role_responsibilities\": \"Develop and enhance server-side automation tests and infrastructure, analyze test results, participate in code reviews, and collaborate with cross-functional teams to ensure high-quality product delivery.\",\n",
    "  \"qualifications_requirements\": \"Minimum 3 years of experience in server-side automation development using Python/Pytest, proficiency with AWS, Docker, Jenkins, Git, and Linux environments, a bachelor's degree in Computer Science or related field, with a background in mathematics or statistics considered an advantage.\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "job_posting_system_prompt += \"\\n here is another real example of a job posting:\\n\"\n",
    "job_posting_system_prompt += \"\"\"\n",
    "{\n",
    "  \"company_name\": \"Earnix\",\n",
    "  \"job_url\": \"https://earnix.com/career/0d.f45/automation-engineer/\",\n",
    "  \"company_location\": \"Givatayim, Israel\",\n",
    "  \"company_size\": \"201-500 employees\",\n",
    "  \"company_description\": \"Earnix is a global provider of AI-driven rating, pricing, and product personalization solutions for insurance and banking, helping financial institutions transform how they make decisions with real-time, dynamic, and integrated analytics.\",\n",
    "  \"role_responsibilities\": \"The Automation Engineer will develop and maintain test automation frameworks, create and execute automated test scripts, collaborate with development teams on CI/CD pipelines, and continuously improve testing methodologies to ensure high-quality software releases.\",\n",
    "  \"qualifications_requirements\": \"Candidates need 3+ years of experience in test automation, proficiency in Python, knowledge of API testing frameworks like REST-assured or Postman, familiarity with CI/CD tools, and strong analytical and problem-solving skills.\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b9392448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to create a user prompt to find the job postings\n",
    "def get_job_postings_user_prompt(text):\n",
    "    user_prompt = \"\"\"here is a text file contains links to job postings. read each link and extract the job posting from it. \\n\n",
    "    Write the summary for each job posting.\\n\"\"\"\n",
    "    user_prompt += text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d5c3d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_job_relevant_system_prompt = \"\"\" You will receive:\n",
    "1. job description summaries (including role, requirements, and expectations).\n",
    "2. A resume in free-text/plain-text format.\n",
    "\n",
    "Your task is to evaluate whether the jobs appear relevant to the candidate based on the skills, experiences, and qualifications in the resume.\n",
    "\n",
    "Instructions:\n",
    "- Compare the core requirements and desired qualifications from the job description to the candidate's experience,\n",
    " skills, education, and achievements in the resume.\n",
    "- Focus on key match indicators such as:\n",
    "  - Required technologies, tools, or methodologies\n",
    "  - Years of experience\n",
    "  - Industry relevance\n",
    "  - Certifications or degrees\n",
    "  - Role-specific accomplishments\n",
    "\n",
    "Respond with the following structure:\n",
    "```json\n",
    "{\n",
    "  \"relevant\": true or false,\n",
    "  \"reasoning\": \"A concise explanation of why the job is or isn't relevant to the candidate.\"\n",
    "}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "28534c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_relevant_user_prompt(resume, job_summaries):\n",
    "    user_prompt = \"Here are the job description summaries and the candidate's resume. \" \\\n",
    "    \"Please assess whether the jobs are relevant to the candidate.\"\n",
    "    user_prompt += \"\"\"The resume: \\n\\n\"\"\"\n",
    "    user_prompt += resume\n",
    "    user_prompt += \"\"\"\\n\\n\n",
    "    The jobs descriptions: \\n\\n\"\"\"\n",
    "    user_prompt += job_summaries\n",
    "    # print(user_prompt)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "917be965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def read_pdf_text(filepath):\n",
    "    try:\n",
    "        text = \"\"\n",
    "        with fitz.open(filepath) as doc:\n",
    "            for page in doc:\n",
    "                text += page.get_text()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error reading PDF: {e}\"\n",
    "    \n",
    "def read_website(url):\n",
    "    try:\n",
    "        website = Website(url)\n",
    "        return website.text\n",
    "    except Exception as e:\n",
    "        return f\"Error reading website: {e}\"\n",
    "    \n",
    "def read_text_file(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error reading text file: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5ce87f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_website_function = {\n",
    "    \"name\": \"read_website\",\n",
    "    \"description\": \"Get the content of the website by its link. Call this whenever you need to read link content, for example when a customer provides a link to a job posting.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"link\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The link to the website you want to read. For example: https://www.example.com/job/software-engineer\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"link\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "52b55349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_tool(reply, messages):\n",
    "    for tool_call in reply.tool_calls:\n",
    "        if tool_call.function.name == \"read_website\":\n",
    "            print(tool_call)\n",
    "            arguments = json.loads(tool_call.function.arguments)\n",
    "            print(arguments)\n",
    "            link = arguments.get('destination_city')\n",
    "            print(link)\n",
    "            website_text = read_website(link)\n",
    "            messages.append(reply)\n",
    "            messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": website_text\n",
    "            })\n",
    "\n",
    "            followup = client.chat.completions.create(\n",
    "                model=deployment,\n",
    "                messages=messages\n",
    "            )\n",
    "\n",
    "            print(\"🔁 Model's final response:\")\n",
    "            print(followup.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d971d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic API call to 4 models\n",
    "def callModel(company, system_prompt, user_prompt):\n",
    "    print(f\"Calling {company}\")\n",
    "    if company == \"ollama\":\n",
    "        response = ollama.chat(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "        )\n",
    "        return response['message']['content']\n",
    "    elif company == \"openai\":\n",
    "        messages = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "        tools = [{\"type\": \"function\", \"function\": read_website_function}]\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment,\n",
    "            messages=messages,\n",
    "            tools=tools\n",
    "        )\n",
    "        reply = response.choices[0].message\n",
    "        if response.choices[0].finish_reason==\"tool_calls\":\n",
    "            final_response = call_tool(reply, messages)\n",
    "            return final_response\n",
    "        else:\n",
    "            return reply.content\n",
    "    elif company == \"anthropic\":\n",
    "        response = claude.messages.create(\n",
    "            model=MODEL_Claude,\n",
    "            max_tokens=500,\n",
    "            temperature=0.4,\n",
    "            system=system_prompt,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "        )\n",
    "        return response.content[0].text\n",
    "    elif company == \"google\":\n",
    "        gemini = google.generativeai.GenerativeModel(\n",
    "            model_name=MODEL_Google,\n",
    "            system_instruction=system_prompt,\n",
    "            )\n",
    "        response = gemini.generate_content(user_prompt)\n",
    "        return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "32696a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the job postings\n",
    "def summarize_job_postings(job_postings):\n",
    "    # Call the model to summarize the job postings\n",
    "    user_prompt = get_job_postings_user_prompt(job_postings)\n",
    "    response = callModel(\"openai\", job_posting_system_prompt, user_prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b076da2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling openai\n",
      "ChatCompletionMessageToolCall(id='call_bJohg0Vr1lyQ9BaAIuztBYkD', function=Function(arguments='{\"link\": \"https://www.linkedin.com/jobs/view/4198542507\"}', name='read_website'), type='function')\n",
      "{'link': 'https://www.linkedin.com/jobs/view/4198542507'}\n",
      "None\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_UrtuKaKa4rHorheDxdUX6or6, call_aD6r7i7E4Jyq3vJ9wGKh9RpL, call_OxAAltAxTwbxGZDGYtjpa2vg, call_maX50lF0VM3KdqVZGfN0pHao, call_x1HXW6lnaxEkfCgvqAhde6pp, call_OP6hRabimlXR0CHhvDJcSuyq, call_O57rhUAsBffJZXjMjgi9daRe, call_sFYnuu8YcRJJYbehnFyQil0H, call_mC7d6tHMjjSOw3vZBTvsfBRj\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[115]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m text = read_text_file(\u001b[33m\"\u001b[39m\u001b[33mjob_links.txt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43msummarize_job_postings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[114]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36msummarize_job_postings\u001b[39m\u001b[34m(job_postings)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msummarize_job_postings\u001b[39m(job_postings):\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# Call the model to summarize the job postings\u001b[39;00m\n\u001b[32m      4\u001b[39m     user_prompt = get_job_postings_user_prompt(job_postings)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     response = \u001b[43mcallModel\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mopenai\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_posting_system_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[113]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mcallModel\u001b[39m\u001b[34m(company, system_prompt, user_prompt)\u001b[39m\n\u001b[32m     24\u001b[39m reply = response.choices[\u001b[32m0\u001b[39m].message\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].finish_reason==\u001b[33m\"\u001b[39m\u001b[33mtool_calls\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     final_response = \u001b[43mcall_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m final_response\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[112]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mcall_tool\u001b[39m\u001b[34m(reply, messages)\u001b[39m\n\u001b[32m     10\u001b[39m messages.append(reply)\n\u001b[32m     11\u001b[39m messages.append({\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtool\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtool_call_id\u001b[39m\u001b[33m\"\u001b[39m: tool_call.id,\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: website_text\n\u001b[32m     15\u001b[39m })\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m followup = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeployment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m🔁 Model\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms final response:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(followup.choices[\u001b[32m0\u001b[39m].message.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/llm_engineering/llms/lib/python3.11/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/llm_engineering/llms/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/llm_engineering/llms/lib/python3.11/site-packages/openai/_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/llm_engineering/llms/lib/python3.11/site-packages/openai/_base_client.py:1034\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m             err.response.read()\n\u001b[32m   1033\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_UrtuKaKa4rHorheDxdUX6or6, call_aD6r7i7E4Jyq3vJ9wGKh9RpL, call_OxAAltAxTwbxGZDGYtjpa2vg, call_maX50lF0VM3KdqVZGfN0pHao, call_x1HXW6lnaxEkfCgvqAhde6pp, call_OP6hRabimlXR0CHhvDJcSuyq, call_O57rhUAsBffJZXjMjgi9daRe, call_sFYnuu8YcRJJYbehnFyQil0H, call_mC7d6tHMjjSOw3vZBTvsfBRj\", 'type': 'invalid_request_error', 'param': 'messages', 'code': None}}"
     ]
    }
   ],
   "source": [
    "text = read_text_file(\"job_links.txt\")\n",
    "summarize_job_postings(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef69de4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
