{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91279c35",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; background-color: #050A0E; border: 1px solid lightblue;\">\n",
    "    <tr>\n",
    "        <td style=\"direction: rtl; text-align: right; color: #FFF8E7; \">\n",
    "            <h2 style=\"color:#FFF8E7;\">JobTonic</h2>\n",
    "            <span style=\"color:#FFF8E7; font-size: 12px\">\n",
    "                ×›×™ ×—×™×¤×•×© ×¢×‘×•×“×” ×¨××•×™ ×œ×”×¨×’×™×© ×›××• ×”×ª×—×œ×” ×—×“×©×”, ×œ× ×›××• ××¡×¢ ××™×™×’×¢.\n",
    "                ×‘××§×•× ×œ×”×™×¡×—×£ ×‘×’×œ×™× ×©×œ ××™×“×¢, \n",
    "                ×ª× ×• ×œ× ×• ×œ×”×™×•×ª ×”×¨×•×— ×©××›×•×•× ×ª ××ª ×”××¤×¨×©.\n",
    "                ×”×›×œ×™\n",
    "                 ××–×§×§ ×¢×‘×•×¨×›× ××ª ××”×•×ª ×›×œ ××©×¨×” â€” ×‘×‘×”×™×¨×•×ª, ×‘××”×™×¨×•×ª, ×•×‘×“×™×•×§ ×©××—×–×™×¨ ×œ×›× ×©×œ×™×˜×”.\n",
    "                ×–×” ×œ× ×¨×§ ×œ×—×¤×© ×¢×‘×•×“×”. ×–×” ×œ×“×™×™×§ ××˜×¨×”. ×–×” ×œ×”×ª×§×“× ×¢× ×¨××© ×¦×œ×•×œ, ×œ×‘ ×¤×ª×•×—, ×•×‘×™×˜×—×•×Ÿ ×××™×ª×™.\n",
    "                ×‘×›×œ ×©×œ×‘ ×‘×“×¨×š â€“ ×× ×—× ×• ×”×× ×¨×’×™×” ×©××–×™×–×” ××ª×›× ×§×“×™××”.\n",
    "            </span>\n",
    "        </td>\n",
    "<td style=\"width: 290px; height: 200px; vertical-align: middle;\">\n",
    "            <img src=\"JobTonic.png\" style=\"width: 100%; height: 100%; display: block;\" />\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b9f46285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "import anthropic\n",
    "import google.generativeai\n",
    "import ollama\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b5a12260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Initialize Google and Anthropic clients\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "MODEL_Claude = \"claude-3-7-sonnet-latest\"\n",
    "claude = anthropic.Anthropic()\n",
    "\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "MODEL_Google = \"gemini-2.0-flash\"\n",
    "google.generativeai.configure()\n",
    "\n",
    "api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "endpoint = os.getenv('ENDPOINT')\n",
    "version = os.getenv('VERSION')\n",
    "deployment = os.getenv('DEPLOYMENT_4_1nano')\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint, \n",
    "    api_key=api_key,\n",
    "    api_version=version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ba200f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with Selenium for dynamic websites.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "\n",
    "        # Set up Selenium WebDriver with Chrome\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--headless')  # Run in headless mode\n",
    "        options.add_argument('--disable-gpu')\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "        # Load the webpage\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Wait for the page to load completely\n",
    "\n",
    "        # Get the page source and parse it with BeautifulSoup\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        driver.quit()  # Close the browser\n",
    "\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "26f344e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The system prompt for job postings\n",
    "job_posting_system_prompt = \"\"\"\n",
    "    You are an assistant specialized in summarizing job postings.\\n\n",
    "    Your task is to extract and clearly summarize three things from the input job description:\\n\n",
    "    1. How the company describes itself.\\n\n",
    "    2. What the day-to-day responsibilities of the role are.\\n\n",
    "    3. What the qualifications or requirements are to apply.\\n\\n\n",
    "    You will be provided with a link to job posting. for example:\\n\n",
    "    https://www.example.com/job/software-engineer or https://www.example.com/job/data-scientist you should extract the relevant information \n",
    "    from the job description and write a summary in plain, professional English. Keep each section concise (1â€“2 sentences).\\n\n",
    "    Do not copy text verbatim unless necessary. Structure your response under the following headers:\\n\n",
    "    - About the Company\\n\n",
    "    - Role Responsibilities\\n\n",
    "    - Qualifications and Requirements\\n\n",
    "    in addition to the following fields:\\n\n",
    "    - Company Name\\n\n",
    "    - Job URL\\n\n",
    "    - Company Location\\n\n",
    "    - Company Size\\n\n",
    "    keep headers empty if the information is not available.\\n\n",
    "\"\"\"\n",
    "job_posting_system_prompt += \"\\nYou should respond in JSON as in this example:\"\n",
    "job_posting_system_prompt += \"\"\"\n",
    "{\n",
    "    \"company_name\": \"Tech Innovations Inc.\",\n",
    "    \"job_url\": \"https://full.url/goes/here/software-engineer\",\n",
    "    \"company_location\": \"San Francisco, CA\",\n",
    "    \"company_size\": \"500+ employees\",\n",
    "    \"company_description\": \"The company is a leading provider of innovative technology solutions.\",\n",
    "    \"role_responsibilities\": \"The role involves developing software applications and collaborating with cross-functional teams.\",\n",
    "    \"qualifications_requirements\": \"Candidates should have a degree in Computer Science and experience with Python.\"\n",
    "}\n",
    "\"\"\"\n",
    "job_posting_system_prompt += \"\\nIn the case that there are no relevant links, respond with an empty JSON object: {}\"\n",
    "\n",
    "job_posting_system_prompt += \"\\n here is a real example of a job posting:\\n\"\n",
    "job_posting_system_prompt += \"\"\"\n",
    "{\n",
    "  \"company_name\": \"Earnix\",\n",
    "  \"job_url\": \"https://earnix.com/career/0d.f45/automation-engineer/\",\n",
    "  \"company_location\": \"Ramat Gan, Israel\",\n",
    "  \"company_size\": \"201â€“500 employees\",\n",
    "  \"company_description\": \"Earnix is a premier provider of cloud-based intelligent decisioning solutions for pricing, rating, underwriting, and product personalization in the insurance and banking sectors, serving clients across over 35 countries.\",\n",
    "  \"role_responsibilities\": \"Develop and enhance server-side automation tests and infrastructure, analyze test results, participate in code reviews, and collaborate with cross-functional teams to ensure high-quality product delivery.\",\n",
    "  \"qualifications_requirements\": \"Minimum 3 years of experience in server-side automation development using Python/Pytest, proficiency with AWS, Docker, Jenkins, Git, and Linux environments, a bachelor's degree in Computer Science or related field, with a background in mathematics or statistics considered an advantage.\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "job_posting_system_prompt += \"\\n here is another real example of a job posting:\\n\"\n",
    "job_posting_system_prompt += \"\"\"\n",
    "{\n",
    "  \"company_name\": \"Earnix\",\n",
    "  \"job_url\": \"https://earnix.com/career/0d.f45/automation-engineer/\",\n",
    "  \"company_location\": \"Givatayim, Israel\",\n",
    "  \"company_size\": \"201-500 employees\",\n",
    "  \"company_description\": \"Earnix is a global provider of AI-driven rating, pricing, and product personalization solutions for insurance and banking, helping financial institutions transform how they make decisions with real-time, dynamic, and integrated analytics.\",\n",
    "  \"role_responsibilities\": \"The Automation Engineer will develop and maintain test automation frameworks, create and execute automated test scripts, collaborate with development teams on CI/CD pipelines, and continuously improve testing methodologies to ensure high-quality software releases.\",\n",
    "  \"qualifications_requirements\": \"Candidates need 3+ years of experience in test automation, proficiency in Python, knowledge of API testing frameworks like REST-assured or Postman, familiarity with CI/CD tools, and strong analytical and problem-solving skills.\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b9392448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to create a user prompt to find the job postings\n",
    "def get_job_postings_user_prompt(text):\n",
    "    user_prompt = \"\"\"here is a link to a job posting. read the content inside the link and extract the job posting from it. \\n\n",
    "    Write the summary to that job posting.\\n\"\"\"\n",
    "    user_prompt += text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d5c3d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_job_relevant_system_prompt = \"\"\" You will receive:\n",
    "1. job description summaries (including role, requirements, and expectations).\n",
    "2. A resume in free-text/plain-text format.\n",
    "\n",
    "Your task is to evaluate whether the jobs appear relevant to the candidate based on the skills, experiences, and qualifications in the resume.\n",
    "\n",
    "Instructions:\n",
    "- Compare the core requirements and desired qualifications from the job description to the candidate's experience,\n",
    " skills, education, and achievements in the resume.\n",
    "- Focus on key match indicators such as:\n",
    "  - Required technologies, tools, or methodologies\n",
    "  - Years of experience\n",
    "  - Industry relevance\n",
    "  - Certifications or degrees\n",
    "  - Role-specific accomplishments\n",
    "\n",
    "Respond with the following structure:\n",
    "```json\n",
    "{\n",
    "  \"relevant\": true or false,\n",
    "  \"reasoning\": \"A concise explanation of why the job is or isn't relevant to the candidate.\"\n",
    "}\n",
    "IF there are more than 3 relevant jobs, return the most relevant 3 jobs only.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "28534c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_relevant_user_prompt(resume, job_summaries):\n",
    "    user_prompt = \"Here are the job description summaries and the candidate's resume. \" \\\n",
    "    \"Please assess whether the jobs are relevant to the candidate. for the jobs that are relevant, \" \\\n",
    "    \"please choose top 3 relevant jobs if you find more than 3.\\n\\n\"\n",
    "    user_prompt += \"\"\"The resume: \\n\\n\"\"\"\n",
    "    user_prompt += resume\n",
    "    user_prompt += \"\"\"\\n\\n\n",
    "    The jobs descriptions: \\n\\n\"\"\"\n",
    "    user_prompt += job_summaries\n",
    "    # print(user_prompt)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "917be965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def read_pdf_text(filepath):\n",
    "    try:\n",
    "        text = \"\"\n",
    "        with fitz.open(filepath) as doc:\n",
    "            for page in doc:\n",
    "                text += page.get_text()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error reading PDF: {e}\"\n",
    "    \n",
    "def read_website(url):\n",
    "    try:\n",
    "        website = Website(url)\n",
    "        return website.text\n",
    "    except Exception as e:\n",
    "        return f\"Error reading website: {e}\"\n",
    "    \n",
    "def read_text_file(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error reading text file: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5ce87f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_website_function = {\n",
    "    \"name\": \"read_website\",\n",
    "    \"description\": \"Get the content of the website by its link. Call this whenever you need to read link content, for example when a customer provides a link to a job posting.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"link\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The link to the website you want to read. For example: https://www.example.com/job/software-engineer\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"link\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "52b55349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_tool(reply, messages): \n",
    "    tool_responses = []\n",
    "    messages.append(reply)\n",
    "\n",
    "    for tool_call in reply.tool_calls:\n",
    "        if tool_call.function.name == \"read_website\":\n",
    "            try:\n",
    "                # print(tool_call)\n",
    "                arguments = json.loads(tool_call.function.arguments)\n",
    "                # print(arguments)\n",
    "                link = arguments.get('link')\n",
    "                print(link)\n",
    "                # Validate the link\n",
    "                if not link or not link.startswith(\"http\"):\n",
    "                    raise ValueError(f\"Invalid link: {link}\")\n",
    "                \n",
    "                website_text = read_website(link)\n",
    "                tool_responses.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": website_text\n",
    "                })\n",
    "                # print(messages)\n",
    "            except Exception as e:\n",
    "                # Handle errors gracefully\n",
    "                error_message = f\"Error processing tool_call_id {tool_call.id}: {e}\"\n",
    "                tool_responses.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": error_message\n",
    "                })\n",
    "\n",
    "        else:\n",
    "            error_message = f\"Error processing tool_call_id {tool_call.id}: Unsupported function {tool_call.function.name}\"\n",
    "            tool_responses.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"content\": error_message\n",
    "            })\n",
    "\n",
    "    messages.extend(tool_responses)\n",
    "    followup = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    # print(\"ğŸ” Model's final response:\")\n",
    "    # print(followup.choices[0].message.content)\n",
    "    return followup.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d971d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic API call to 4 models\n",
    "def callModel(company, system_prompt, user_prompt):\n",
    "    print(f\"Calling {company}\")\n",
    "    if company == \"ollama\":\n",
    "        response = ollama.chat(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "        )\n",
    "        return response['message']['content']\n",
    "    elif company == \"openai\":\n",
    "        messages = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "        tools = [{\"type\": \"function\", \"function\": read_website_function}]\n",
    "        response = client.chat.completions.create(\n",
    "            model=deployment,\n",
    "            messages=messages,\n",
    "            tools=tools\n",
    "        )\n",
    "        reply = response.choices[0].message\n",
    "        if response.choices[0].finish_reason==\"tool_calls\":\n",
    "            final_response = call_tool(reply, messages)\n",
    "            return final_response\n",
    "        else:\n",
    "            return reply.content\n",
    "    elif company == \"anthropic\":\n",
    "        response = claude.messages.create(\n",
    "            model=MODEL_Claude,\n",
    "            max_tokens=500,\n",
    "            temperature=0.4,\n",
    "            system=system_prompt,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "        )\n",
    "        return response.content[0].text\n",
    "    elif company == \"google\":\n",
    "        gemini = google.generativeai.GenerativeModel(\n",
    "            model_name=MODEL_Google,\n",
    "            system_instruction=system_prompt,\n",
    "            )\n",
    "        response = gemini.generate_content(user_prompt)\n",
    "        return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "32696a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the job postings\n",
    "def summarize_job_postings(job_postings):\n",
    "    # Call the model to summarize the job postings\n",
    "    user_prompt = get_job_postings_user_prompt(job_postings)\n",
    "    response = callModel(\"openai\", job_posting_system_prompt, user_prompt)\n",
    "    return response\n",
    "\n",
    "def is_job_relevant(resume, job_summaries):\n",
    "    # Call the model to check if the job is relevant\n",
    "    user_prompt = get_job_relevant_user_prompt(resume, job_summaries)\n",
    "    response = callModel(\"anthropic\", is_job_relevant_system_prompt, user_prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b076da2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling openai\n",
      "https://www.linkedin.com/jobs/view/4198542507\n",
      "Calling openai\n",
      "https://www.linkedin.com/jobs/view/4232412234\n",
      "Calling openai\n",
      "https://www.linkedin.com/jobs/view/4178550672\n",
      "Calling openai\n",
      "https://www.linkedin.com/jobs/view/4182302831\n",
      "Calling openai\n",
      "https://www.linkedin.com/jobs/view/4204803730\n",
      "Calling openai\n",
      "https://www.linkedin.com/jobs/view/4233645366\n",
      "Calling openai\n",
      "https://www.linkedin.com/jobs/view/4224390764\n",
      "Calling openai\n",
      "https://www.linkedin.com/jobs/view/4231163915\n",
      "Calling openai\n",
      "https://www.linkedin.com/jobs/view/4228188455\n",
      "Calling openai\n",
      "https://www.linkedin.com/jobs/view/4198824423\n"
     ]
    }
   ],
   "source": [
    "text = read_text_file(\"job_links.txt\")\n",
    "links = [link.strip() for link in text.split(\",\") if link.strip()]\n",
    "\n",
    "all_summaries = []\n",
    "for link in links:\n",
    "    try:\n",
    "        summary = summarize_job_postings(link)\n",
    "        all_summaries.append({\n",
    "            \"link\": link,\n",
    "            \"summary\": summary\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {link}: {e}\")\n",
    "        all_summaries.append({\n",
    "            \"link\": link,\n",
    "            \"summary\": f\"Error: {e}\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1ef69de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All summaries:\n",
      "Link: [\n",
      "  \"https://www.linkedin.com/jobs/view/4198542507\"\n",
      "Summary: {\n",
      "    \"company_name\": \"Cytactic\",\n",
      "    \"job_url\": \"https://www.linkedin.com/jobs/view/4198542507\",\n",
      "    \"company_location\": \"Tel Aviv-Yafo, Tel Aviv District, Israel\",\n",
      "    \"company_size\": null,\n",
      "    \"company_description\": \"Cytactic is a cybersecurity startup at the forefront of innovation, combining generative AI with real-world security challenges.\",\n",
      "    \"role_responsibilities\": \"Design, develop, and deploy AI solutions leveraging Large Language Models (LLMs), optimize models, develop AI systems and agents, enhance retrieval-augmented pipelines, execute data engineering tasks, and manage cloud infrastructure on AWS.\",\n",
      "    \"qualifications_requirements\": \"Candidates should have at least 2 years of experience in AI or data science, proficiency in Python, hands-on experience with LLMs, prompt engineering, model fine-tuning, AWS services, and collaborative software development skills. A degree in a quantitative field is preferred.\"\n",
      "}\n",
      "--------------------------------------------------------------------------------\n",
      "Link: \"https://www.linkedin.com/jobs/view/4232412234\"\n",
      "Summary: {\n",
      "    \"company_name\": \"Armis\",\n",
      "    \"job_url\": \"https://www.linkedin.com/jobs/view/4232412234\",\n",
      "    \"company_location\": \"Gilat\",\n",
      "    \"company_size\": null,\n",
      "    \"company_description\": \"Armis is a cyber exposure management and security company that protects the attack surface and manages organizational cyber risks in real time, securing Fortune 100, 200, and 500 companies, as well as governments and critical infrastructure.\",\n",
      "    \"role_responsibilities\": \"Design, develop, and deploy AI agents to improve Go-to-Market functions by integrating various data sources, refining prompts, and collaborating with stakeholders to evaluate performance and implement AI solutions using advanced tools like LLMs and vector databases.\",\n",
      "    \"qualifications_requirements\": \"At least 2 years of experience in software development or data science focusing on AI projects, proficiency in Python and AI/ML libraries, experience with APIs and data sources, and strong analytical and communication skills; preferred experience with AI agents, vector databases, cloud platforms, and understanding of GTM processes.\"\n",
      "}\n",
      "--------------------------------------------------------------------------------\n",
      "Link: \"https://www.linkedin.com/jobs/view/4178550672\"\n",
      "Summary: {\n",
      "    \"company_name\": \"Varos\",\n",
      "    \"job_url\": \"https://www.linkedin.com/jobs/view/4178550672\",\n",
      "    \"company_location\": \"Tel Aviv-Yafo, Israel\",\n",
      "    \"company_size\": null,\n",
      "    \"company_description\": \"Varos is focused on building end-to-end AI solutions, including AI Agents and RAG Search, and is actively involved in innovation and research in AI to solve real-world business problems.\",\n",
      "    \"role_responsibilities\": \"The AI Engineer will develop AI solutions by integrating and orchestrating LLMs and AI services, research and implement agent-based architectures and prompt strategies, collaborate with cross-functional teams, and ensure AI solutions are scalable, secure, and efficient.\",\n",
      "    \"qualifications_requirements\": \"Proficiency in Python and AI/ML frameworks like PyTorch or TensorFlow, experience in developing AI/NLP products in production, strong problem-solving skills, and the ability to communicate technical concepts effectively.\"\n",
      "}\n",
      "--------------------------------------------------------------------------------\n",
      "Link: \"https://www.linkedin.com/jobs/view/4182302831\"\n",
      "Summary: {\n",
      "    \"company_name\": \"Legit Security\",\n",
      "    \"job_url\": \"https://www.linkedin.com/jobs/view/4182302831\",\n",
      "    \"company_location\": \"Israel\",\n",
      "    \"company_size\": \"\",\n",
      "    \"company_description\": \"Legit Security develops a cybersecurity product that enhances application security posture management, helping organizations secure their software development lifecycle and transform into a secure-SDLC.\",\n",
      "    \"role_responsibilities\": \"The AI engineer will design AI architectures using generative AI, create proofs of concept, develop prompts for secure and accurate AI execution, build data pipelines, and collaborate with teams to leverage AI for product improvements and data-driven decision-making.\",\n",
      "    \"qualifications_requirements\": \"Candidates should have experience with AI models and large language models, prompt engineering, data analysis, working with data lakes and vector databases, and demonstrate high-level collaboration and problem-solving skills.\"\n",
      "}\n",
      "--------------------------------------------------------------------------------\n",
      "Link: \"https://www.linkedin.com/jobs/view/4204803730\"\n",
      "Summary: {\n",
      "    \"company_name\": \"Navan\",\n",
      "    \"job_url\": \"https://www.linkedin.com/jobs/view/4204803730\",\n",
      "    \"company_location\": \"Tel Aviv-Yafo, Israel\",\n",
      "    \"company_size\": \"Not specified\",\n",
      "    \"company_description\": \"Navan is developing AI-powered travel and expense management products with advanced backend services that incorporate large language models and conversational AI.\",\n",
      "    \"role_responsibilities\": \"Design and develop scalable backend services, integrate AI platforms and services, translate AI capabilities into features, and ensure the performance, security, and reliability of AI-powered systems in collaboration with product and engineering teams.\",\n",
      "    \"qualifications_requirements\": \"At least 2 years of backend engineering experience, proficiency in one or more programming languages, experience with APIs, distributed systems, databases, cloud platforms, and familiarity with AI/ML platforms and technologies.\"\n",
      "}\n",
      "--------------------------------------------------------------------------------\n",
      "Link: \"https://www.linkedin.com/jobs/view/4233645366\"\n",
      "Summary: {\n",
      "    \"company_name\": \"CommBox\",\n",
      "    \"job_url\": \"https://www.linkedin.com/jobs/view/4233645366\",\n",
      "    \"company_location\": \"Gilat Yam, Center District, Israel\",\n",
      "    \"company_size\": null,\n",
      "    \"company_description\": \"CommBox is revolutionizing customer communication with an automated platform that enhances customer satisfaction, ROI, and business growth through innovative technology.\",\n",
      "    \"role_responsibilities\": \"Assist in transforming language model capabilities into reliable products via prompt engineering, data experimentation, and collaboration with various teams; develop Python scripts and tools; document workflows and test plans; support onboarding and project delivery; troubleshoot and improve internal processes.\",\n",
      "    \"qualifications_requirements\": \"Enrollment in a B.Sc. in Computer Science or similar, proficiency in Python and API concepts, basic understanding of ML concepts, analytical and communication skills, ability to multitask, and proactive problem-solving attitude.\"\n",
      "}\n",
      "--------------------------------------------------------------------------------\n",
      "Link: \"https://www.linkedin.com/jobs/view/4224390764\"\n",
      "Summary: {\n",
      "    \"company_name\": \"Finout\",\n",
      "    \"job_url\": \"https://www.linkedin.com/jobs/view/4224390764\",\n",
      "    \"company_location\": \"Tel Aviv-Yafo, Israel\",\n",
      "    \"company_size\": null,\n",
      "    \"company_description\": \"Finout is a company developing a FinOps SaaS platform that leverages AI capabilities to enhance cloud spend analysis, automate insights, and create innovative product features.\",\n",
      "    \"role_responsibilities\": \"Design, develop, and deploy generative AI features for the company's platform; identify AI integration opportunities; prototype new use cases; collaborate with cross-functional teams; stay current with AI advancements; implement safeguards and optimize model performance.\",\n",
      "    \"qualifications_requirements\": \"Minimum 3 years of software engineering experience, including 1-2 years working on generative AI projects; proficiency in Python or similar languages; experience with prompt engineering, AWS services, MLOps, and model deployment; creativity, strong communication skills, and ability to go from idea to production.\"\n",
      "}\n",
      "--------------------------------------------------------------------------------\n",
      "Link: \"https://www.linkedin.com/jobs/view/4231163915\"\n",
      "Summary: {\n",
      "    \"company_name\": \"Finout\",\n",
      "    \"job_url\": \"https://www.linkedin.com/jobs/view/4231163915\",\n",
      "    \"company_location\": \"Tel Aviv District, Israel\",\n",
      "    \"company_size\": \"\",\n",
      "    \"company_description\": \"Finout provides a rich dataset covering all aspects of a companyâ€™s cloud spend, enabling the development of intelligent, value-driven features in their FinOps SaaS platform. They focus on innovation, user impact, and leveraging AI capabilities.\",\n",
      "    \"role_responsibilities\": \"Design, build, and deploy generative AI-powered features, identify AI integration opportunities, prototype new AI use cases, collaborate across teams, stay current with AI advancements, and optimize model performance and safety.\",\n",
      "    \"qualifications_requirements\": \"At least 3 years of software engineering experience including 1-2 years with generative AI projects, proficiency in Python or similar, experience with prompt engineering, AWS services, MLOps, and strong communication skills. Nice-to-haves include experience in FinOps, NLP, open-source contributions, and responsible AI knowledge.\"\n",
      "}\n",
      "--------------------------------------------------------------------------------\n",
      "Link: \"https://www.linkedin.com/jobs/view/4228188455\"\n",
      "Summary: {\n",
      "    \"company_name\": \"Hear\",\n",
      "    \"job_url\": \"https://www.linkedin.com/jobs/view/4228188455\",\n",
      "    \"company_location\": \"Gilat, Tel Aviv District, Israel\",\n",
      "    \"company_size\": \"\",\n",
      "    \"company_description\": \"Hear is an innovative early-stage startup focused on shaping the future of conversational intelligence, emphasizing AI, technology, and real-world problem solving in a collaborative environment.\",\n",
      "    \"role_responsibilities\": \"Design, develop, and deploy AI solutions, including machine learning models for audio processing, integrate AI models into end-user applications on GCP, optimize models for scalability and performance, and stay updated with the latest AI/ML research to foster innovation.\",\n",
      "    \"qualifications_requirements\": \"Minimum of 3 years of experience with machine learning frameworks, a degree in Computer Science or related field with a focus on AI/ML, strong background in data science and algorithms, familiarity with GCP and deployment/monitoring tools like DataDog, and a passion for innovation.\"\n",
      "}\n",
      "--------------------------------------------------------------------------------\n",
      "Link: \"https://www.linkedin.com/jobs/view/4198824423\"\n",
      "]\n",
      "Summary: {\n",
      "  \"company_name\": \"Dig\",\n",
      "  \"job_url\": \"https://www.linkedin.com/jobs/view/4198824423\",\n",
      "  \"company_location\": \"Gilat, Tel Aviv District, Israel\",\n",
      "  \"company_size\": \"Unknown\",\n",
      "  \"company_description\": \"Dig is an innovative startup focused on leveraging AI for social media monitoring, brand protection, and real-time marketing, providing actionable insights across social media channels.\",\n",
      "  \"role_responsibilities\": \"The AI Software Engineer will lead the development and evaluation of algorithms in production, optimize LLM-based features for cost and latency, and work collaboratively with backend and frontend teams to deploy AI-driven solutions.\",\n",
      "  \"qualifications_requirements\": \"Candidates should have a B.Sc. in CS or EE, a minimum of 6 years industry experience in engineering to production, strong Python skills, experience with cloud environments, and familiarity with LLM libraries is preferred.\"\n",
      "}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"All summaries:\")\n",
    "for summary in all_summaries:\n",
    "    print(f\"Link: {summary['link']}\")\n",
    "    print(f\"Summary: {summary['summary']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f285356a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling anthropic\n",
      "Job relevance response:\n",
      "I've analyzed the job descriptions and the candidate's resume to determine relevance. Here are my findings:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"relevant\": true,\n",
      "  \"reasoning\": \"The candidate has strong software engineering experience with Python, has recently been studying LLM engineering (including RAG, prompt engineering, and AI agents), and has experience with AWS, databases, and data analysis. The top 3 most relevant positions are with Cytactic, Armis, and Varos, as they align well with the candidate's recent focus on Generative AI and their technical background.\"\n",
      "}\n",
      "```\n",
      "\n",
      "The top 3 most relevant jobs for this candidate are:\n",
      "\n",
      "1. **Cytactic (AI Engineer)**: This role requires 2+ years of AI/data science experience, Python proficiency, and hands-on experience with LLMs and prompt engineering. The candidate has Python experience, is currently studying LLM engineering (including prompt engineering), and has worked with data analysis and AWS, making this a strong match.\n",
      "\n",
      "2. **Armis (AI Agent Engineer)**: This position requires 2+ years of software development experience with AI focus, Python proficiency, and experience with APIs and data sources. The candidate meets these requirements with their software engineering background, Python skills, and recent LLM engineering training that includes AI agents.\n",
      "\n",
      "3. **Varos (AI Engineer)**: This role requires Python proficiency and experience with AI/ML frameworks. The candidate's software engineering background, Python skills, and recent focus on LLM engineering (including RAG implementation and agent design) align well with the responsibilities of developing AI solutions and implementing agent-based architectures.\n"
     ]
    }
   ],
   "source": [
    "resume = read_pdf_text(\"SapirShamay.pdf\")\n",
    "summaries = \"/n\".join([f\"link: {summary['link']}\\n summary:\\n{summary['summary']}\\n\" for summary in all_summaries])\n",
    "response = is_job_relevant(resume, summaries)\n",
    "print(\"Job relevance response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a48ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
