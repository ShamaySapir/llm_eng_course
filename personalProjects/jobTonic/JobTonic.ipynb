{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91279c35",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; background-color: #050A0E; border: 1px solid lightblue;\">\n",
    "    <tr>\n",
    "        <td style=\"direction: rtl; text-align: right; color: #FFF8E7; \">\n",
    "            <h2 style=\"color:#FFF8E7;\">JobTonic</h2>\n",
    "            <span style=\"color:#FFF8E7; font-size: 12px\">\n",
    "                כי חיפוש עבודה ראוי להרגיש כמו התחלה חדשה, לא כמו מסע מייגע.\n",
    "                במקום להיסחף בגלים של מידע, \n",
    "                תנו לנו להיות הרוח שמכוונת את המפרש.\n",
    "                הכלי\n",
    "                 מזקק עבורכם את מהות כל משרה — בבהירות, במהירות, ובדיוק שמחזיר לכם שליטה.\n",
    "                זה לא רק לחפש עבודה. זה לדייק מטרה. זה להתקדם עם ראש צלול, לב פתוח, וביטחון אמיתי.\n",
    "                בכל שלב בדרך – אנחנו האנרגיה שמזיזה אתכם קדימה.\n",
    "            </span>\n",
    "        </td>\n",
    "<td style=\"width: 290px; height: 200px; vertical-align: middle;\">\n",
    "            <img src=\"JobTonic.png\" style=\"width: 100%; height: 100%; display: block;\" />\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b9f46285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import google.generativeai\n",
    "import ollama\n",
    "from PIL import Image\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b5a12260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Initialize Google and Anthropic clients\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "MODEL_Claude = \"claude-3-7-sonnet-latest\"\n",
    "claude = anthropic.Anthropic()\n",
    "\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "MODEL_Google = \"gemini-2.0-flash\"\n",
    "google.generativeai.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ba200f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with Selenium for dynamic websites.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "\n",
    "        # Set up Selenium WebDriver with Chrome\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--headless')  # Run in headless mode\n",
    "        options.add_argument('--disable-gpu')\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "        # Load the webpage\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Wait for the page to load completely\n",
    "\n",
    "        # Get the page source and parse it with BeautifulSoup\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        driver.quit()  # Close the browser\n",
    "\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d971d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic API call to 3 models\n",
    "def callModel(company, system_prompt, user_prompt):\n",
    "    print(f\"Calling {company}\")\n",
    "    if company == \"ollama\":\n",
    "        response = ollama.chat(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "        )\n",
    "        return response['message']['content']\n",
    "    elif company == \"anthropic\":\n",
    "        response = claude.messages.create(\n",
    "            model=MODEL_Claude,\n",
    "            max_tokens=500,\n",
    "            temperature=0.4,\n",
    "            system=system_prompt,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "        )\n",
    "        return response.content[0].text\n",
    "    elif company == \"google\":\n",
    "        gemini = google.generativeai.GenerativeModel(\n",
    "            model_name=MODEL_Google,\n",
    "            system_instruction=system_prompt,\n",
    "            )\n",
    "        response = gemini.generate_content(user_prompt)\n",
    "        return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "26f344e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The system prompt for job postings\n",
    "job_posting_system_prompt = (\n",
    "    \"You are an assistant specialized in summarizing job postings.\\n\"\n",
    "    \"Your task is to extract and clearly summarize three things from the input job description:\\n\"\n",
    "    \"1. How the company describes itself.\\n\"\n",
    "    \"2. What the day-to-day responsibilities of the role are.\\n\"\n",
    "    \"3. What the qualifications or requirements are to apply.\\n\\n\"\n",
    "    \"Write the summary in plain, professional English. Keep each section concise (1–2 sentences).\\n\"\n",
    "    \"Do not copy text verbatim unless necessary. Structure your response under the following headers:\\n\"\n",
    "    \"- About the Company\\n\"\n",
    "    \"- Role Responsibilities\\n\"\n",
    "    \"- Qualifications and Requirements\\n\"\n",
    "    \"in addition to the following fields:\\n\"\n",
    "    \"- Company Name\\n\"\n",
    "    \"- Job URL\\n\"\n",
    "    \"- Company Location\\n\"\n",
    "    \"- Company Size\\n\"\n",
    ")\n",
    "job_posting_system_prompt += \"\\nYou should respond in JSON as in this example:\"\n",
    "job_posting_system_prompt += \"\"\"\n",
    "{\n",
    "    \"company_name\": \"Tech Innovations Inc.\",\n",
    "    \"job_url\": \"https://full.url/goes/here/software-engineer\",\n",
    "    \"company_location\": \"San Francisco, CA\",\n",
    "    \"company_size\": \"500+ employees\",\n",
    "    \"company_description\": \"The company is a leading provider of innovative technology solutions.\",\n",
    "    \"role_responsibilities\": \"The role involves developing software applications and collaborating with cross-functional teams.\",\n",
    "    \"qualifications_requirements\": \"Candidates should have a degree in Computer Science and experience with Python.\"\n",
    "}\n",
    "\"\"\"\n",
    "job_posting_system_prompt += \"\\nIn the case that there are no relevant links, respond with an empty JSON object: {}\"\n",
    "\n",
    "job_posting_system_prompt += \"\\n here is a real example of a job posting:\\n\"\n",
    "job_posting_system_prompt += \"\"\"\n",
    "{\n",
    "  \"company_name\": \"Earnix\",\n",
    "  \"job_url\": \"https://earnix.com/career/0d.f45/automation-engineer/\",\n",
    "  \"company_location\": \"Ramat Gan, Israel\",\n",
    "  \"company_size\": \"201–500 employees\",\n",
    "  \"company_description\": \"Earnix is a premier provider of cloud-based intelligent decisioning solutions for pricing, rating, underwriting, and product personalization in the insurance and banking sectors, serving clients across over 35 countries.\",\n",
    "  \"role_responsibilities\": \"Develop and enhance server-side automation tests and infrastructure, analyze test results, participate in code reviews, and collaborate with cross-functional teams to ensure high-quality product delivery.\",\n",
    "  \"qualifications_requirements\": \"Minimum 3 years of experience in server-side automation development using Python/Pytest, proficiency with AWS, Docker, Jenkins, Git, and Linux environments, a bachelor's degree in Computer Science or related field, with a background in mathematics or statistics considered an advantage.\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "job_posting_system_prompt += \"\\n here is another real example of a job posting:\\n\"\n",
    "job_posting_system_prompt += \"\"\"\n",
    "{\n",
    "  \"company_name\": \"Earnix\",\n",
    "  \"job_url\": \"https://earnix.com/career/0d.f45/automation-engineer/\",\n",
    "  \"company_location\": \"Givatayim, Israel\",\n",
    "  \"company_size\": \"201-500 employees\",\n",
    "  \"company_description\": \"Earnix is a global provider of AI-driven rating, pricing, and product personalization solutions for insurance and banking, helping financial institutions transform how they make decisions with real-time, dynamic, and integrated analytics.\",\n",
    "  \"role_responsibilities\": \"The Automation Engineer will develop and maintain test automation frameworks, create and execute automated test scripts, collaborate with development teams on CI/CD pipelines, and continuously improve testing methodologies to ensure high-quality software releases.\",\n",
    "  \"qualifications_requirements\": \"Candidates need 3+ years of experience in test automation, proficiency in Python, knowledge of API testing frameworks like REST-assured or Postman, familiarity with CI/CD tools, and strong analytical and problem-solving skills.\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b9392448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to create a user prompt to find the job postings\n",
    "def get_job_postings_user_prompt(text):\n",
    "    user_prompt = \"Please analyze the following job description:\\n\\n\"\n",
    "    user_prompt += text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d5c3d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_job_relevant_system_prompt = \"\"\" You will receive:\n",
    "1. A job description summary (including role, requirements, and expectations).\n",
    "2. A resume in free-text/plain-text format.\n",
    "\n",
    "Your task is to evaluate whether the job appears relevant to the candidate based on the skills, experiences, and qualifications in the resume.\n",
    "\n",
    "Instructions:\n",
    "- Compare the core requirements and desired qualifications from the job description to the candidate's experience,\n",
    " skills, education, and achievements in the resume.\n",
    "- Focus on key match indicators such as:\n",
    "  - Required technologies, tools, or methodologies\n",
    "  - Years of experience\n",
    "  - Industry relevance\n",
    "  - Certifications or degrees\n",
    "  - Role-specific accomplishments\n",
    "\n",
    "Respond with the following structure:\n",
    "```json\n",
    "{\n",
    "  \"relevant\": true or false,\n",
    "  \"reasoning\": \"A concise explanation of why the job is or isn't relevant to the candidate.\"\n",
    "}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "28534c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_relevant_user_prompt(resume, job_summary):\n",
    "    user_prompt = \"Here is the job description summary and the candidate's resume. \" \\\n",
    "    \"Please assess whether the job is relevant to the candidate.\"\n",
    "    user_prompt += \"\"\"The resume: \\n\\n\"\"\"\n",
    "    user_prompt += resume\n",
    "    user_prompt += \"\"\"\\n\\n\n",
    "    The job description: \\n\\n\"\"\"\n",
    "    user_prompt += job_summary\n",
    "    # print(user_prompt)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a2a79bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "\n",
    "def read_docx_text(filepath):\n",
    "    try:\n",
    "        doc = Document(filepath)\n",
    "        text = '\\n'.join([para.text for para in doc.paragraphs if para.text.strip() != ''])\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error reading DOCX: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "da38590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def read_pdf_text(filepath):\n",
    "    try:\n",
    "        text = \"\"\n",
    "        with fitz.open(filepath) as doc:\n",
    "            for page in doc:\n",
    "                text += page.get_text()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error reading PDF: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e45deda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_file(file_name):\n",
    "    try:\n",
    "        with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return f\"Error reading text file: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0ca06998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function get a url of job posting and answer the user if it can apply to it\n",
    "def job_agent(resume_file, txt):\n",
    "    # Read the resume file\n",
    "    resume = read_pdf_text(resume_file)\n",
    "    # Call text model to get the job posting summary\n",
    "    job_summary = callModel(\"anthropic\", job_posting_system_prompt, get_job_postings_user_prompt(txt))\n",
    "    # Call the model to check if the job is relevant\n",
    "    is_relevant = callModel(\"anthropic\", is_job_relevant_system_prompt, get_job_relevant_user_prompt(resume, job_summary))\n",
    "    answer = job_summary + \"\\n\\n\" + is_relevant\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "266ef003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDUCATION\n",
      "BEN-GURION UNIVERSITY \n",
      "BSc in Software and Information System\n",
      "Engineering (Avg - 83)\n",
      "2018 - 2022\n",
      "2025 - Current\n",
      "LLM ENGINEERING: MASTER AI, LARGE\n",
      "LANGUAGE MODELS & AGENTS\n",
      "CONTACT\n",
      "(972) 50 6910190\n",
      "shamay.sapir@gmail.com\n",
      "linkedin.com/in/sapir-shamay\n",
      "WORK EXPERIENCE\n",
      "2021-2025\n",
      "Simplex (by Nuvei)\n",
      "Senior R&D analyst\n",
      "2019-2020\n",
      "Wix\n",
      "Software Engineer\n",
      "2013-2015\n",
      "MAMRAM, IDF\n",
      "Software Developer, Team Leader - Captain\n",
      "Tech lead and backend engineer in the company’s payments infrastructure, responsible for\n",
      "mission-critical components powering hundreds of thousands of transactions a month.\n",
      "Designed and implemented high-impact, cross-team features in Python, deployed to internal\n",
      "payment gateways at scale, leading to a 0.5% uplift in conversion rate.\n",
      "Led the full technical lifecycle: authored design docs, set Git flow standards, enforced PEP8 with\n",
      "linters, increased test coverage by 5%, and streamlined the code review pipeline.\n",
      "Working across multiple environments including production, simulation, and a custom\n",
      "challenger staging environment – allowing safe traffic mirroring and performance\n",
      "benchmarking before promoting to prod.\n",
      "Used tools like Datadog, New Relic, Redash, and Amplitude for monitoring, logging, and product\n",
      "analytics.\n",
      "In rare cases, executed rollbacks based on performance gaps identified via large-scale SQL\n",
      "analysis using DataGrip.\n",
      "Built internal reusable Python packages to accelerate development.\n",
      "Worked with both relational (PostgreSQL, SQL Server) and graph databases (Neo4j, Amazon\n",
      "Neptune).\n",
      "Collaborated with DevOps on CI/CD pipelines (Jenkins), and ensured compliance with GDPR\n",
      "and best practices in data handling.\n",
      "Led onboarding of 4 new data analysts: built structured learning paths, delivered training\n",
      "sessions, and orchestrated their integration.\n",
      "Acted as Scrum Master, prioritizing tasks with leadership and assigning work aligned with both\n",
      "urgency and personal growth trajectories.\n",
      "Frontend engineer in the Wix’s Editor team, contributing to 6 high-scale products (1M+ MAUs each).\n",
      "Led end-to-end feature development in a Agile environment, collaborating with product and\n",
      "design.\n",
      "Delivered performant, accessible, and cross-browser features using React, vanilla JavaScript, and\n",
      "CSS, with a strong emphasis on component reusability and design system integration via\n",
      "Storybook.\n",
      "Resolved critical edge-case bugs by implementing low-level polyfills, ensuring robust support\n",
      "across diverse browsers.\n",
      "Worked with CI/CD pipelines, Jest and Cypress for testing, and utilized Feature Flags and A/B\n",
      "Testing via internal tooling to enable data-driven rollouts.\n",
      "Led, designed, and built cross-organizational software solutions for the central HR division of the\n",
      "IDF, affecting tens of thousands of users.\n",
      "Technical PM, Team Leader - Lieutenant\n",
      "2012-2013\n",
      "Managed a squad of 3-6 developers, QA, and PMs, maintaining the main IDF HR platform written in\n",
      "a Hebrew procedural language compiled to PL/I on an IBM mainframe.\n",
      "Sapir Shamay\n",
      "S o f t w a r e  E n g i n e e r  |  G e n  A I  G e e k\n",
      "SKILLS\n",
      "Python\n",
      "Generative AI (RAG, prompt engineering,\n",
      "agent design – beginner/intermediate\n",
      "level)\n",
      "AI/ML Tools: Scikit-learn, Pandas, NumPy,\n",
      "TensorFlow (basic)\n",
      "DevOps: Git, Jenkins\n",
      "Cloud Platforms: AWS, Azure\n",
      "DBs: PostgreSQL, SQL Server\n",
      "AI & Data Tools: Databricks, PySpark, Jupyter\n",
      "Notebooks\n",
      "Technical Storytelling – explaining complex\n",
      "topics in a simple, engaging way\n",
      "Team Collaboration & Cross-functional\n",
      "Communication\n",
      "Fast Learner with a passion for cutting-edge\n",
      "technologies\n",
      "English \n",
      "Hebrew \n",
      "LANGUAGES\n",
      "Hands-on training in LLMs and AI agents, including:\n",
      "RAG implementation, function calling, and prompt engineering\n",
      "Projects: AI brochure generator, multi-modal support agent, code assistant\n",
      "Focus on LLM evaluation, optimization, and real-world applications\n",
      "LLM ENGINEERING: MASTER AI, LARGE LANGUAGE MODELS & AGENTS\n",
      "UDEMY\n",
      "Software engineer with over a decade of experience in the tech industry, specializing in software\n",
      "development and data analysis. I contributed to the development of a machine learning model for\n",
      "fraud detection by designing and implementing the features used by the model. \n",
      "Recently, I’ve been diving into the world of Generative AI, with a clear goal of specializing in this\n",
      "fascinating and fast-evolving field. I'm eager to join projects that combine cutting-edge innovation\n",
      "with real user value, while bringing strong communication skills, creative thinking, and a high\n",
      "standard of excellence to every team I join.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resume_file = \"SapirShamay.pdf\"\n",
    "print(read_pdf_text(resume_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "065fe11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "job_search_url = \"https://www.factify.com/careers\"\n",
    "job_file = \"jobDescription.txt\"\n",
    "resume_file = \"SapirShamay.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c9ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if website\n",
    "job_search_url = \"https://www.factify.com/careers\"\n",
    "website = Website(job_search_url)\n",
    "answer = job_agent(resume_file, website.text)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "33d64838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling anthropic\n",
      "Calling anthropic\n",
      "Calling anthropic\n",
      "{\n",
      "  \"company_name\": \"Factify\",\n",
      "  \"job_url\": \"\",\n",
      "  \"company_location\": \"Israel\",\n",
      "  \"company_size\": \"\",\n",
      "  \"company_description\": \"Factify is an early-stage Silicon Valley company developing an enterprise document platform that transforms documents through their Smarter Document format, disrupting a $500 billion industry with revolutionary document experience, applications, and enterprise AI.\",\n",
      "  \"role_responsibilities\": \"The Backend Engineer will design and implement production-grade APIs, build scalable microservices using Python and Go, develop AI infrastructure components, create robust data persistence layers, and implement observability and monitoring solutions across distributed systems.\",\n",
      "  \"qualifications_requirements\": \"Candidates need 3+ years of experience building distributed backend systems, strong proficiency in Python and Go, experience with gRPC/REST APIs, hands-on experience with cloud platforms and containerization technologies, and database management skills.\"\n",
      "}\n",
      "\n",
      "I'll evaluate whether this job is relevant to the candidate based on the provided information.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"relevant\": true,\n",
      "  \"reasoning\": \"The candidate has relevant experience that matches the Backend Engineer role requirements. They have worked as a Senior R&D analyst at Simplex and as a Software Engineer at Wix, demonstrating backend engineering experience. Their technical skills include Python (a required language), experience with APIs, cloud platforms (AWS, Azure), databases (PostgreSQL, SQL Server), and DevOps tools. While Go isn't explicitly mentioned in their resume, their strong Python background and demonstrated ability to learn new technologies (currently studying LLM Engineering) suggest adaptability. The candidate has worked with distributed systems at scale, implemented monitoring solutions (Datadog, New Relic), and has experience with containerization environments - all key requirements for the role. Their recent focus on AI/ML also aligns with the AI infrastructure components mentioned in the job description.\"\n",
      "}\n",
      "```\n",
      "{\n",
      "  \"company_name\": \"Factify\",\n",
      "  \"job_url\": \"\",\n",
      "  \"company_location\": \"Israel\",\n",
      "  \"company_size\": \"\",\n",
      "  \"company_description\": \"Factify is an early-stage Silicon Valley company developing an enterprise document platform that transforms documents through their Smarter Document format, disrupting a $500 billion industry with revolutionary document experience, applications, and enterprise AI.\",\n",
      "  \"role_responsibilities\": \"The Backend Engineer will design and implement production-grade APIs, build scalable microservices using Python and Go, develop AI infrastructure components, create robust data persistence layers, and implement observability and monitoring solutions across distributed systems.\",\n",
      "  \"qualifications_requirements\": \"Candidates need 3+ years of experience building distributed backend systems, strong proficiency in Python and Go, experience with gRPC/REST APIs, hands-on experience with cloud platforms and containerization technologies, and database management skills.\"\n",
      "}\n",
      "\n",
      "I'll evaluate whether this job is relevant to the candidate based on the provided information.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"relevant\": true,\n",
      "  \"reasoning\": \"The candidate has relevant experience that matches the Backend Engineer role requirements. They have worked as a Senior R&D analyst at Simplex and as a Software Engineer at Wix, demonstrating backend engineering experience. Their technical skills include Python (a required language), experience with APIs, cloud platforms (AWS, Azure), databases (PostgreSQL, SQL Server), and DevOps tools. While Go isn't explicitly mentioned in their resume, their strong Python background and demonstrated ability to learn new technologies (currently studying LLM Engineering) suggest adaptability. The candidate has worked with distributed systems at scale, implemented monitoring solutions (Datadog, New Relic), and has experience with containerization environments - all key requirements for the role. Their recent focus on AI/ML also aligns with the AI infrastructure components mentioned in the job description.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# if file\n",
    "job_file = \"jobDescription.txt\"\n",
    "answer = job_agent(resume_file, read_text_file(job_file))\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cda5ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt =\"You are an expert resume writer specializing in tailoring resumes to specific\" \\\n",
    "\" job descriptions. Given the following resume document provided  and the following job description\" \\\n",
    "\" in this url: https://earnix.com/career/ae.559/junior-software-developer-genai-systems/, \" \\\n",
    "\"rewrite the resume text to:* Prioritize skills and experiences most relevant to the job description.\" \\\n",
    "\"* Incorporate keywords and phrases from the job description to optimize for Applicant Tracking Systems\" \\\n",
    "\" (ATS).* Use strong action verbs and professional language.* Maintain the original structure\" \\\n",
    "\" and information hierarchy of the resume.* Focus on rephrasing the content, \" \\\n",
    "\"do not add new information not present in the original resume.* \" \\\n",
    "\"Please rewrite this document in plain text format only, keeping the original \" \\\n",
    "\"section titles (like Profile, Employment History, etc.). Use blank lines to \" \\\n",
    "\"separate roles or sections. Do not include explanations or markdown. This will be converted directly \" \\\n",
    "\"into a .docx file later.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeba339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"company_name\": \"Earnix\",\n",
      "  \"job_url\": \"https://earnix.com/career/\",\n",
      "  \"company_location\": \"Ramat Gan, IL\",\n",
      "  \"company_size\": \"201-500 employees\",\n",
      "  \"company_description\": \"Earnix is a premier provider of mission-critical, cloud-based intelligent decisioning across pricing, rating, underwriting, and product personalization solutions. They offer fully-integrated solutions designed to transform how global insurers and banks are run.\",\n",
      "  \"role_responsibilities\": \"The Fullstack BI Developer will design and develop full-stack BI solutions from database to dashboards, build and maintain ETL pipelines and data models, and work with cross-functional teams to deliver impactful analytics.\",\n",
      "  \"qualifications_requirements\": \"The role requires 3-5 years of experience in both frontend and backend BI development, a bachelor's degree in a relevant field, a strong understanding of data warehousing concepts and ETL processes, and experience with Snowflake, Tableau, and SQL. Experience with Rivery and Python is a plus.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "response = job_postings(\"google\", job_posting_system_prompt, user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11abd7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
